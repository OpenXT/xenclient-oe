--- a/coregrind/m_syswrap/syswrap-linux.c	2013-10-23 11:50:12.000000000 +0100
+++ b/coregrind/m_syswrap/syswrap-linux.c	2014-01-08 18:33:52.000000000 +0000
@@ -6917,6 +6917,56 @@
                     (Addr)args->arr, sizeof(*(args->arr)) * args->num);
       break;
    }
+   case VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR: {
+       struct vki_xen_privcmd_mmapcacheattr *args =
+           (struct vki_xen_privcmd_mmapcacheattr *)(ARG3);
+       PRE_MEM_READ("VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR(addr)",
+                    (Addr)&args->addr, sizeof(args->addr));
+       PRE_MEM_READ("VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR(type)",
+                    (Addr)args->type, sizeof(args->type));
+      break;
+   }
+
+   case VKI_XEN_IOCTL_EVTCHN_BIND_VIRQ: {
+      struct vki_xen_evtchn_bind_virq *args =
+          (struct vki_xen_evtchn_bind_virq *)(ARG3);
+      PRE_FIELD_READ("VKI_XEN_EVTCHN_BIND_VIRQ(virq)",
+                     args->virq);
+      break;
+   }
+   case VKI_XEN_IOCTL_EVTCHN_BIND_INTERDOMAIN: {
+      struct vki_xen_evtchn_bind_interdomain *args =
+          (struct vki_xen_evtchn_bind_interdomain *)(ARG3);
+      PRE_FIELD_READ("VKI_XEN_EVTCHN_BIND_INTERDOMAIN(remote_domain)",
+                     args->remote_domain);
+      PRE_FIELD_READ("VKI_XEN_EVTCHN_BIND_INTERDOMAIN(remote_port)",
+                     args->remote_port);
+      break;
+   }
+   case VKI_XEN_IOCTL_EVTCHN_BIND_UNBOUND_PORT: {
+      struct vki_xen_evtchn_bind_unbound_port *args =
+          (struct vki_xen_evtchn_bind_unbound_port *)(ARG3);
+      PRE_FIELD_READ("VKI_XEN_EVTCHN_BIND_UNBOUND_PORT(remote_domain)",
+                     args->remote_domain);
+      break;
+   }
+   case VKI_XEN_IOCTL_EVTCHN_UNBIND: {
+      struct vki_xen_evtchn_unbind *args =
+          (struct vki_xen_evtchn_unbind *)(ARG3);
+      PRE_FIELD_READ("VKI_XEN_EVTCHN_UNBIND(port)",
+                     args->port);
+      break;
+   }
+   case VKI_XEN_IOCTL_EVTCHN_NOTIFY: {
+      struct vki_xen_evtchn_notify *args =
+          (struct vki_xen_evtchn_notify *)(ARG3);
+      PRE_FIELD_READ("VKI_XEN_IOCTL_EVTCHN_NOTIFY(port)", args->port);
+      break;
+   }
+   case VKI_XEN_IOCTL_EVTCHN_RESET:
+      /* No input argument. */
+      break;
+
 #endif
 
    default:
@@ -7973,6 +8023,18 @@
        POST_MEM_WRITE((Addr)args->err, sizeof(*(args->err)) * args->num);
       }
       break;
+   case VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR:
+      /* No output. */
+      break;
+
+   case VKI_XEN_IOCTL_EVTCHN_BIND_VIRQ:
+   case VKI_XEN_IOCTL_EVTCHN_BIND_INTERDOMAIN:
+   case VKI_XEN_IOCTL_EVTCHN_BIND_UNBOUND_PORT:
+   case VKI_XEN_IOCTL_EVTCHN_UNBIND:
+   case VKI_XEN_IOCTL_EVTCHN_NOTIFY:
+   case VKI_XEN_IOCTL_EVTCHN_RESET:
+      /* No output. */
+      break;
 #endif
 
    default:
--- a/coregrind/m_syswrap/syswrap-xen.c	2013-10-23 11:50:12.000000000 +0100
+++ b/coregrind/m_syswrap/syswrap-xen.c	2014-01-08 18:33:52.000000000 +0000
@@ -152,10 +152,35 @@
       break;
    }
 
+   case VKI_XENMEM_add_to_physmap: {
+      struct vki_xen_add_to_physmap *arg =
+          (struct vki_xen_add_to_physmap*)(unsigned int)ARG2;
+
+      PRE_MEM_READ("XENMEM_add_to_physmap", (Addr)&arg->domid, sizeof (arg->domid));
+      PRE_MEM_READ("XENMEM_add_to_physmap", (Addr)&arg->size, sizeof (arg->size));
+      PRE_MEM_READ("XENMEM_add_to_physmap", (Addr)&arg->space, sizeof (arg->space));
+      PRE_MEM_READ("XENMEM_add_to_physmap", (Addr)&arg->idx, sizeof (arg->idx));
+      PRE_MEM_READ("XENMEM_add_to_physmap", (Addr)&arg->gpfn, sizeof (arg->gpfn));
+      break;
+   }
+
    case VKI_XENMEM_get_sharing_freed_pages:
    case VKI_XENMEM_get_sharing_shared_pages:
       break;
 
+   case VKI_XENMEM_translate_gpfn_list: {
+      struct vki_xen_translate_gpfn_list *arg =
+          (struct vki_xen_translate_gpfn_list *)(unsigned int)ARG2;
+
+      PRE_MEM_READ("XENMEM_translate_gpfn_list domid",
+                   (Addr)&arg->domid, sizeof(arg->domid));
+      PRE_MEM_READ("XENMEM_translate_gpfn_list nr_gpfns",
+                   (Addr)&arg->nr_gpfns, sizeof(arg->nr_gpfns));
+      PRE_MEM_READ("XENMEM_translate_gpfn_list gpfn_list",
+                   (Addr)&arg->gpfn_list, sizeof(arg->gpfn_list));
+       break;
+   }
+
    default:
       bad_subop(tid, layout, arrghs, status, flags,
                 "__HYPERVISOR_memory_op", ARG1);
@@ -544,6 +569,10 @@
       PRE_XEN_DOMCTL_READ(hypercall_init, gmfn);
       break;
 
+   case VKI_XEN_DOMCTL_settimeoffset:
+      PRE_XEN_DOMCTL_READ(settimeoffset, time_offset_seconds);
+      break;
+
    case VKI_XEN_DOMCTL_getvcpuinfo:
       PRE_XEN_DOMCTL_READ(getvcpuinfo, vcpu);
       break;
@@ -615,6 +644,21 @@
       __PRE_XEN_DOMCTL_READ(getvcpuextstate, vcpuextstate, buffer);
       break;
 
+   case VKI_XEN_DOMCTL_test_assign_device:
+     __PRE_XEN_DOMCTL_READ(test_assign_device, assign_device, machine_sbdf);
+     break;
+
+   case VKI_XEN_DOMCTL_iommu_map_batch:
+     PRE_XEN_DOMCTL_READ(iommu_map_batch, gfn);
+     PRE_XEN_DOMCTL_READ(iommu_map_batch, nr);
+     break;
+
+   case VKI_XEN_DOMCTL_pin_mem_cacheattr:
+     PRE_XEN_DOMCTL_READ(pin_mem_cacheattr, start);
+     PRE_XEN_DOMCTL_READ(pin_mem_cacheattr, end);
+     PRE_XEN_DOMCTL_READ(pin_mem_cacheattr, type);
+     break;
+
    default:
       bad_subop(tid, layout, arrghs, status, flags,
                 "__HYPERVISOR_domctl", domctl->cmd);
@@ -624,6 +668,59 @@
 #undef __PRE_XEN_DOMCTL_READ
 }
 
+PRE(sched_op)
+{
+   unsigned long op = ARG1;
+   void *arg = (void *)(unsigned long)ARG2;
+
+   PRINT("__HYPERVISOR_sched_op ( %ld, %p )", op, arg);
+
+#define __PRE_XEN_SCHEDOP_READ(_sched_op, _type, _field)    \
+   PRE_MEM_READ("XEN_SCHEDOP_" # _sched_op "." #_field,     \
+                (Addr)&((_type*)arg)->_field,               \
+                sizeof(((_type*)arg)->_field))
+#define PRE_XEN_SCHEDOP_READ(_sched_op, _field) \
+   __PRE_XEN_SCHEDOP_READ(_sched_op, struct vki_xen_sched_ ## _sched_op, _field)
+
+   switch (op) {
+   case VKI_XEN_SCHEDOP_yield:
+   case VKI_XEN_SCHEDOP_block:
+      /* No input argument. */
+      break;
+
+   case VKI_XEN_SCHEDOP_shutdown:
+      PRE_XEN_SCHEDOP_READ(shutdown, reason);
+      break;
+
+   case VKI_XEN_SCHEDOP_poll:
+      PRE_XEN_SCHEDOP_READ(poll, ports);
+      PRE_XEN_SCHEDOP_READ(poll, nr_ports);
+      PRE_XEN_SCHEDOP_READ(poll, timeout);
+      break;
+
+   case VKI_XEN_SCHEDOP_remote_shutdown:
+      PRE_XEN_SCHEDOP_READ(remote_shutdown, domain_id);
+      PRE_XEN_SCHEDOP_READ(remote_shutdown, reason);
+      break;
+
+   case VKI_XEN_SCHEDOP_shutdown_code:
+      /* No input argument. */
+      break;
+
+   case VKI_XEN_SCHEDOP_watchdog:
+      PRE_XEN_SCHEDOP_READ(watchdog, timeout);
+      break;
+
+   default:
+      bad_subop(tid, layout, arrghs, status, flags,
+                "__HYPERVISOR_sched_op", op);
+      break;
+   }
+
+#undef PRE_XEN_SCHEDOP_READ
+#undef __PRE_XEN_SHCEDOP_READ
+}
+
 PRE(hvm_op)
 {
    unsigned long op = ARG1;
@@ -632,11 +729,11 @@
    PRINT("__HYPERVISOR_hvm_op ( %ld, %p )", op, arg);
 
 #define __PRE_XEN_HVMOP_READ(_hvm_op, _type, _field)    \
-   PRE_MEM_READ("XEN_HVMOP_" # _hvm_op " " #_field,     \
+   PRE_MEM_READ("XEN_HVMOP_" # _hvm_op "." #_field,     \
                 (Addr)&((_type*)arg)->_field,           \
                 sizeof(((_type*)arg)->_field))
 #define PRE_XEN_HVMOP_READ(_hvm_op, _field)                             \
-   __PRE_XEN_HVMOP_READ(_hvm_op, "xen_hvm_" # _hvm_op "_t", _field)
+   __PRE_XEN_HVMOP_READ(_hvm_op, struct vki_xen_hvm_ ## _hvm_op, _field)
 
    switch (op) {
    case VKI_XEN_HVMOP_set_param:
@@ -650,6 +747,106 @@
       __PRE_XEN_HVMOP_READ(get_param, struct vki_xen_hvm_param, index);
       break;
 
+   case VKI_XEN_HVMOP_set_isa_irq_level:
+      PRE_XEN_HVMOP_READ(set_isa_irq_level, domid);
+      PRE_XEN_HVMOP_READ(set_isa_irq_level, isa_irq);
+      PRE_XEN_HVMOP_READ(set_isa_irq_level, level);
+      break;
+
+   case VKI_XEN_HVMOP_set_pci_link_route:
+      PRE_XEN_HVMOP_READ(set_pci_link_route, domid);
+      PRE_XEN_HVMOP_READ(set_pci_link_route, link);
+      PRE_XEN_HVMOP_READ(set_pci_link_route, isa_irq);
+      break;
+
+   case VKI_XEN_HVMOP_track_dirty_vram:
+      PRE_XEN_HVMOP_READ(track_dirty_vram, domid);
+      PRE_XEN_HVMOP_READ(track_dirty_vram, first_pfn);
+      PRE_XEN_HVMOP_READ(track_dirty_vram, nr);
+      break;
+
+   case VKI_XEN_HVMOP_modified_memory:
+      PRE_XEN_HVMOP_READ(modified_memory, domid);
+      PRE_XEN_HVMOP_READ(modified_memory, first_pfn);
+      PRE_XEN_HVMOP_READ(modified_memory, nr);
+      break;
+
+   case VKI_XEN_HVMOP_set_mem_type:
+      PRE_XEN_HVMOP_READ(set_mem_type, domid);
+      PRE_XEN_HVMOP_READ(set_mem_type, hvmmem_type);
+      PRE_XEN_HVMOP_READ(set_mem_type, nr);
+      PRE_XEN_HVMOP_READ(set_mem_type, first_pfn);
+      break;
+
+   case VKI_XEN_HVMOP_pagetable_dying:
+      PRE_XEN_HVMOP_READ(pagetable_dying, domid);
+      PRE_XEN_HVMOP_READ(pagetable_dying, gpa);
+      break;
+
+   case VKI_XEN_HVMOP_get_time:
+      /* No input argument */
+      break;
+
+   case VKI_XEN_HVMOP_xentrace:
+      PRE_XEN_HVMOP_READ(xentrace, event);
+      //__PRE_XEN_HVMOP_READ(xentrace, struct vki_xen_hvm_xentrace, extra_bytes);
+      break;
+
+   case VKI_XEN_HVMOP_set_mem_access:
+      PRE_XEN_HVMOP_READ(set_mem_access, domid);
+      PRE_XEN_HVMOP_READ(set_mem_access, hvmmem_access);
+      PRE_XEN_HVMOP_READ(set_mem_access, nr);
+      PRE_XEN_HVMOP_READ(set_mem_access, first_pfn);
+      break;
+
+   case VKI_XEN_HVMOP_get_mem_access:
+      PRE_XEN_HVMOP_READ(get_mem_access, domid);
+      PRE_XEN_HVMOP_READ(get_mem_access, pfn);
+      break;
+
+   case VKI_XEN_HVMOP_inject_trap:
+      PRE_XEN_HVMOP_READ(inject_trap, domid);
+      PRE_XEN_HVMOP_READ(inject_trap, vcpuid);
+      PRE_XEN_HVMOP_READ(inject_trap, vector);
+      PRE_XEN_HVMOP_READ(inject_trap, type);
+      PRE_XEN_HVMOP_READ(inject_trap, error_code);
+      PRE_XEN_HVMOP_READ(inject_trap, insn_len);
+      PRE_XEN_HVMOP_READ(inject_trap, cr2);
+      break;
+
+   case VKI_XEN_HVMOP_register_ioreq_server:
+      PRE_XEN_HVMOP_READ(register_ioreq_server, domid);
+      break;
+
+   case VKI_XEN_HVMOP_get_ioreq_server_buf_channel:
+      PRE_XEN_HVMOP_READ(get_ioreq_server_buf_channel, domid);
+      PRE_XEN_HVMOP_READ(get_ioreq_server_buf_channel, id);
+      break;
+
+   case VKI_XEN_HVMOP_map_io_range_to_ioreq_server:
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, domid);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, is_mmio);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, id);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, s);
+      PRE_XEN_HVMOP_READ(map_io_range_to_ioreq_server, e);
+      break;
+
+   case VKI_XEN_HVMOP_unmap_io_range_from_ioreq_server:
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, domid);
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, is_mmio);
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, id);
+      PRE_XEN_HVMOP_READ(unmap_io_range_from_ioreq_server, addr);
+      break;
+
+   case VKI_XEN_HVMOP_register_pcidev:
+      PRE_XEN_HVMOP_READ(register_pcidev, domid);
+      PRE_XEN_HVMOP_READ(register_pcidev, id);
+      PRE_XEN_HVMOP_READ(register_pcidev, domain);
+      PRE_XEN_HVMOP_READ(register_pcidev, bus);
+      PRE_XEN_HVMOP_READ(register_pcidev, device);
+      PRE_XEN_HVMOP_READ(register_pcidev, function);
+      break;
+
    default:
       bad_subop(tid, layout, arrghs, status, flags,
                 "__HYPERVISOR_hvm_op", op);
@@ -662,6 +859,7 @@
 POST(memory_op)
 {
    switch (ARG1) {
+   case VKI_XENMEM_add_to_physmap:
    case VKI_XENMEM_set_memory_map:
    case VKI_XENMEM_decrease_reservation:
    case VKI_XENMEM_claim_pages:
@@ -681,6 +879,14 @@
    case VKI_XENMEM_get_sharing_shared_pages:
        /* No outputs */
        break;
+
+   case VKI_XENMEM_translate_gpfn_list: {
+       struct vki_xen_translate_gpfn_list *memory_reservation =
+           (struct vki_xen_translate_gpfn_list *)ARG2;
+       POST_MEM_WRITE((Addr)&memory_reservation->mfn_list,
+                      sizeof(vki_xen_pfn_t) * memory_reservation->nr_gpfns);
+       break;
+   }
    }
 }
 
@@ -1039,6 +1245,35 @@
 #undef __POST_XEN_DOMCTL_WRITE
 }
 
+POST(sched_op)
+{
+   unsigned long op = ARG1;
+   //void *arg = (void *)(unsigned long)ARG2;
+
+#define __POST_XEN_SCHEDOP_WRITE(_sched_op, _type, _field)  \
+      POST_MEM_WRITE((Addr)&((_type*)arg)->_field,      \
+                     sizeof(((_type*)arg)->_field))
+#define POST_XEN_SCHEDOP_WRITE(_sched_op, _field) \
+      __POST_XEN_SCHEDOP_READ(_sched_op, struct vki_xen_sched_ ## _sched_op, _field)
+
+   switch (op) {
+   case VKI_XEN_SCHEDOP_yield:
+   case VKI_XEN_SCHEDOP_block:
+   case VKI_XEN_SCHEDOP_shutdown:
+   case VKI_XEN_SCHEDOP_poll:
+   case VKI_XEN_SCHEDOP_remote_shutdown:
+   case VKI_XEN_SCHEDOP_shutdown_code:
+   case VKI_XEN_SCHEDOP_watchdog:
+      /* No ouput. */
+      break;
+   default:
+      break;
+   }
+
+#undef POST_XEN_SCHEDOP_WRITE
+#undef __POST_XEN_SCHEDOP_WRITE
+}
+
 POST(hvm_op)
 {
    unsigned long op = ARG1;
@@ -1048,7 +1283,7 @@
       POST_MEM_WRITE((Addr)&((_type*)arg)->_field,      \
                      sizeof(((_type*)arg)->_field))
 #define POST_XEN_HVMOP_WRITE(_hvm_op, _field) \
-      __PRE_XEN_HVMOP_READ(_hvm_op, "xen_hvm_" # _hvm_op "_t", _field)
+      __POST_XEN_HVMOP_WRITE(_hvm_op, struct vki_xen_hvm_ ## _hvm_op, _field)
 
    switch (op) {
    case VKI_XEN_HVMOP_set_param:
@@ -1058,6 +1293,43 @@
    case VKI_XEN_HVMOP_get_param:
       __POST_XEN_HVMOP_WRITE(get_param, struct vki_xen_hvm_param, value);
       break;
+
+   case VKI_XEN_HVMOP_set_isa_irq_level:
+   case VKI_XEN_HVMOP_set_pci_link_route:
+   case VKI_XEN_HVMOP_modified_memory:
+   case VKI_XEN_HVMOP_set_mem_type:
+   case VKI_XEN_HVMOP_pagetable_dying:
+   case VKI_XEN_HVMOP_xentrace:
+   case VKI_XEN_HVMOP_set_mem_access:
+   case VKI_XEN_HVMOP_inject_trap:
+      /* No output parameter */
+      break;
+
+   case VKI_XEN_HVMOP_track_dirty_vram:
+      POST_XEN_HVMOP_WRITE(track_dirty_vram, dirty_bitmap);
+      break;
+
+   case VKI_XEN_HVMOP_get_time:
+      POST_XEN_HVMOP_WRITE(get_time, now);
+      break;
+
+   case VKI_XEN_HVMOP_get_mem_access:
+      POST_XEN_HVMOP_WRITE(get_mem_access, hvmmem_access);
+      break;
+
+   case VKI_XEN_HVMOP_register_ioreq_server:
+      POST_XEN_HVMOP_WRITE(register_ioreq_server, id);
+      break;
+
+   case VKI_XEN_HVMOP_get_ioreq_server_buf_channel:
+      POST_XEN_HVMOP_WRITE(get_ioreq_server_buf_channel, channel);
+      break;
+
+   case VKI_XEN_HVMOP_map_io_range_to_ioreq_server:
+   case VKI_XEN_HVMOP_unmap_io_range_from_ioreq_server:
+   case VKI_XEN_HVMOP_register_pcidev:
+      /* No output parameter */
+      break;
    }
 #undef __POST_XEN_HVMOP_WRITE
 #undef POST_XEN_HVMOP_WRITE
@@ -1112,7 +1384,7 @@
    HYPXY(__VKI_XEN_mmuext_op,               mmuext_op,         2), // 26
    //    __VKI_XEN_xsm_op                                          // 27
    //    __VKI_XEN_nmi_op                                          // 28
-   //    __VKI_XEN_sched_op                                        // 29
+   HYPXY(__VKI_XEN_sched_op,                sched_op,          2), // 29
 
    //    __VKI_XEN_callback_op                                     // 30
    //    __VKI_XEN_xenoprof_op                                     // 31
--- a/include/Makefile.am	2013-10-23 11:49:54.000000000 +0100
+++ b/include/Makefile.am	2014-01-08 18:33:52.000000000 +0000
@@ -67,6 +67,7 @@
 	vki/vki-scnums-mips64-linux.h	\
 	vki/vki-scnums-darwin.h         \
 	vki/vki-xen.h                   \
+	vki/vki-xen-sched.h		\
 	vki/vki-xen-domctl.h		\
 	vki/vki-xen-evtchn.h		\
 	vki/vki-xen-gnttab.h		\
--- a/include/vki/vki-linux.h	2013-10-23 11:49:54.000000000 +0100
+++ b/include/vki/vki-linux.h	2014-01-08 18:33:52.000000000 +0000
@@ -3122,11 +3122,48 @@
         int __user *err;  /* array of error codes */
 };
 
+struct vki_xen_privcmd_mmapcacheattr {
+	__vki_u64 addr;
+	int type;
+};
+
 #define VKI_XEN_IOCTL_PRIVCMD_HYPERCALL    _VKI_IOC(_VKI_IOC_NONE, 'P', 0, sizeof(struct vki_xen_privcmd_hypercall))
 #define VKI_XEN_IOCTL_PRIVCMD_MMAP         _VKI_IOC(_VKI_IOC_NONE, 'P', 2, sizeof(struct vki_xen_privcmd_mmap))
 
 #define VKI_XEN_IOCTL_PRIVCMD_MMAPBATCH    _VKI_IOC(_VKI_IOC_NONE, 'P', 3, sizeof(struct vki_xen_privcmd_mmapbatch))
 #define VKI_XEN_IOCTL_PRIVCMD_MMAPBATCH_V2 _VKI_IOC(_VKI_IOC_NONE, 'P', 4, sizeof(struct vki_xen_privcmd_mmapbatch_v2))
+#define VKI_XEN_IOCTL_PRIVCMD_MMAPCACHEATTR	_VKI_IOC(_VKI_IOC_NONE, 'P', 200, sizeof (struct vki_xen_privcmd_mmapcacheattr))
+
+//----------------------------------------------------------------------
+// Xen evtchn IOCTL
+//----------------------------------------------------------------------
+
+struct vki_xen_evtchn_bind_virq {
+    unsigned int virq;
+};
+
+struct vki_xen_evtchn_bind_interdomain {
+    unsigned int remote_domain, remote_port;
+};
+
+struct vki_xen_evtchn_bind_unbound_port {
+    unsigned int remote_domain;
+};
+
+struct vki_xen_evtchn_unbind {
+    unsigned int port;
+};
+
+struct vki_xen_evtchn_notify {
+    unsigned int port;
+};
+
+#define VKI_XEN_IOCTL_EVTCHN_BIND_VIRQ          _VKI_IOC(_VKI_IOC_NONE, 'E', 0, sizeof(struct vki_xen_evtchn_bind_virq))
+#define VKI_XEN_IOCTL_EVTCHN_BIND_INTERDOMAIN   _VKI_IOC(_VKI_IOC_NONE, 'E', 1, sizeof(struct vki_xen_evtchn_bind_interdomain))
+#define VKI_XEN_IOCTL_EVTCHN_BIND_UNBOUND_PORT  _VKI_IOC(_VKI_IOC_NONE, 'E', 2, sizeof(struct vki_xen_evtchn_bind_unbound_port))
+#define VKI_XEN_IOCTL_EVTCHN_UNBIND             _VKI_IOC(_VKI_IOC_NONE, 'E', 3, sizeof(struct vki_xen_evtchn_unbind))
+#define VKI_XEN_IOCTL_EVTCHN_NOTIFY             _VKI_IOC(_VKI_IOC_NONE, 'E', 4, sizeof(struct vki_xen_evtchn_notify))
+#define VKI_XEN_IOCTL_EVTCHN_RESET              _VKI_IOC(_VKI_IOC_NONE, 'E', 5, 0)
 
 //----------------------------------------------------------------------
 // From linux-3.4.0/include/linux/fs.h
--- a/include/vki/vki-xen-domctl.h	2013-10-23 11:49:54.000000000 +0100
+++ b/include/vki/vki-xen-domctl.h	2014-01-08 18:33:52.000000000 +0000
@@ -84,6 +84,7 @@
 #define VKI_XEN_DOMCTL_set_broken_page_p2m           67
 #define VKI_XEN_DOMCTL_setnodeaffinity               68
 #define VKI_XEN_DOMCTL_getnodeaffinity               69
+#define VKI_XEN_DOMCTL_iommu_map_batch		     94
 #define VKI_XEN_DOMCTL_gdbsx_guestmemio            1000
 #define VKI_XEN_DOMCTL_gdbsx_pausevcpu             1001
 #define VKI_XEN_DOMCTL_gdbsx_unpausevcpu           1002
@@ -225,6 +226,22 @@
     vki_xen_uint64_aligned_t  gmfn;           /* GMFN to be initialised */
 };
 
+struct vki_xen_domctl_settimeoffset {
+    vki_int32_t time_offset_seconds;
+};
+
+struct vki_xen_domctl_iommu_map_batch {
+    vki_xen_uint64_aligned_t gfn;
+    vki_xen_uint64_aligned_t nr;
+    VKI_XEN_GUEST_HANDLE_64(vki_uint64) mfns;
+};
+
+struct vki_xen_domctl_pin_mem_cacheattr {
+    vki_xen_uint64_aligned_t start;
+    vki_xen_uint64_aligned_t end;
+    vki_uint32_t type;
+};
+
 struct vki_xen_domctl_cpuid {
   vki_uint32_t input[2];
   vki_uint32_t eax;
@@ -259,6 +276,10 @@
     vki_uint32_t size;
 };
 
+struct vki_xen_domctl_assign_device {
+    vki_uint32_t machine_sbdf;
+};
+
 struct vki_xen_domctl {
     vki_uint32_t cmd;
     vki_uint32_t interface_version; /* XEN_DOMCTL_INTERFACE_VERSION */
@@ -287,7 +308,7 @@
         //struct vki_xen_domctl_ioport_permission ioport_permission;
         struct vki_xen_domctl_hypercall_init    hypercall_init;
         //struct vki_xen_domctl_arch_setup        arch_setup;
-        //struct vki_xen_domctl_settimeoffset     settimeoffset;
+        struct vki_xen_domctl_settimeoffset     settimeoffset;
         //struct vki_xen_domctl_disable_migrate   disable_migrate;
         struct vki_xen_domctl_tsc_info          tsc_info;
         //struct vki_xen_domctl_real_mode_area    real_mode_area;
@@ -296,11 +317,12 @@
         struct vki_xen_domctl_address_size      address_size;
         //struct vki_xen_domctl_sendtrigger       sendtrigger;
         //struct vki_xen_domctl_get_device_group  get_device_group;
-        //struct vki_xen_domctl_assign_device     assign_device;
+        struct vki_xen_domctl_assign_device     assign_device;
         //struct vki_xen_domctl_bind_pt_irq       bind_pt_irq;
         //struct vki_xen_domctl_memory_mapping    memory_mapping;
+        struct vki_xen_domctl_iommu_map_batch   iommu_map_batch;
         //struct vki_xen_domctl_ioport_mapping    ioport_mapping;
-        //struct vki_xen_domctl_pin_mem_cacheattr pin_mem_cacheattr;
+        struct vki_xen_domctl_pin_mem_cacheattr pin_mem_cacheattr;
         //struct vki_xen_domctl_ext_vcpucontext   ext_vcpucontext;
         //struct vki_xen_domctl_set_target        set_target;
         //struct vki_xen_domctl_subscribe         subscribe;
--- a/include/vki/vki-xen.h	2013-10-23 11:49:54.000000000 +0100
+++ b/include/vki/vki-xen.h	2014-01-08 18:33:52.000000000 +0000
@@ -84,6 +84,7 @@
 #include <vki/vki-xen-gnttab.h>
 #include <vki/vki-xen-version.h>
 #include <vki/vki-xen-hvm.h>
+#include <vki/vki-xen-sched.h>
 
 #endif // __VKI_XEN_H
 
--- a/include/vki/vki-xen-hvm.h	2013-10-23 11:49:54.000000000 +0100
+++ b/include/vki/vki-xen-hvm.h	2014-01-08 18:33:52.000000000 +0000
@@ -5,13 +5,136 @@
 #define VKI_XEN_HVMOP_set_param           0
 #define VKI_XEN_HVMOP_get_param           1
 struct vki_xen_hvm_param {
-    vki_xen_domid_t  domid;    /* IN */
-    vki_uint32_t index;    /* IN */
-    vki_uint64_t value;    /* IN/OUT */
+    vki_xen_domid_t  domid; /* IN */
+    vki_uint32_t index;     /* IN */
+    vki_uint64_t value;     /* IN/OUT */
 };
 
-#endif // __VKI_XEN_HVM_H
+#define VKI_XEN_HVMOP_set_isa_irq_level   3
+struct vki_xen_hvm_set_isa_irq_level {
+    vki_xen_domid_t  domid; /* IN */
+    vki_uint8_t  isa_irq;   /* IN */
+    vki_uint8_t  level;     /* IN */
+};
+
+#define VKI_XEN_HVMOP_set_pci_link_route  4
+struct vki_xen_hvm_set_pci_link_route {
+    vki_xen_domid_t  domid; /* IN */
+    vki_uint8_t  link;      /* IN */
+    vki_uint8_t  isa_irq;   /* IN */
+};
+
+#define VKI_XEN_HVMOP_track_dirty_vram    6
+struct vki_xen_hvm_track_dirty_vram {
+    vki_xen_domid_t  domid;                             /* IN */
+    vki_xen_uint64_aligned_t first_pfn;                 /* IN */
+    vki_xen_uint64_aligned_t nr;                        /* IN */
+    VKI_XEN_GUEST_HANDLE_64(vki_uint8) dirty_bitmap;    /* OUT */
+};
+
+#define VKI_XEN_HVMOP_modified_memory    7
+struct vki_xen_hvm_modified_memory {
+    vki_xen_domid_t  domid;             /* IN */
+    vki_xen_uint64_aligned_t first_pfn; /* IN */
+    vki_xen_uint64_aligned_t nr;        /* IN */
+};
+
+#define VKI_XEN_HVMOP_set_mem_type    8
+struct vki_xen_hvm_set_mem_type {
+    vki_xen_domid_t domid;              /* IN */
+    vki_uint16_t hvmmem_type;           /* IN */
+    vki_uint32_t nr;                    /* IN */
+    vki_xen_uint64_aligned_t first_pfn; /* IN */
+};
+
+#define VKI_XEN_HVMOP_pagetable_dying        9
+struct vki_xen_hvm_pagetable_dying {
+    vki_xen_domid_t  domid;         /* IN */
+    vki_uint16_t pad[3];            /* align next field on 8-byte boundary */
+    vki_uint64_t gpa;               /* IN */
+};
+
+#define VKI_XEN_HVMOP_get_time              10
+struct vki_xen_hvm_get_time {
+    vki_uint64_t now;   /* OUT */
+};
+
+#define VKI_XEN_HVMOP_xentrace              11
+struct vki_xen_hvm_xentrace {
+    vki_uint16_t event;                                                     /* IN */
+    vki_uint16_t extra_bytes;                                               /* IN */
+#define __XEN_HVM_TRACE_EXTRA_MAX 7
+    vki_uint8_t extra[__XEN_HVM_TRACE_EXTRA_MAX * sizeof(vki_uint32_t)];    /* IN */
+};
 
+#define VKI_XEN_HVMOP_set_mem_access        12
+struct vki_xen_hvm_set_mem_access {
+    vki_xen_domid_t domid;              /* IN */
+    vki_uint16_t hvmmem_access;         /* IN */
+    vki_uint32_t nr;                    /* IN */
+    vki_xen_uint64_aligned_t first_pfn; /* IN */
+};
+
+#define VKI_XEN_HVMOP_get_mem_access        13
+struct vki_xen_hvm_get_mem_access {
+    vki_xen_domid_t domid;          /* IN */
+    vki_uint16_t hvmmem_access;     /* OUT */
+    vki_xen_uint64_aligned_t pfn;   /* IN */
+};
+
+#define VKI_XEN_HVMOP_inject_trap            14
+struct vki_xen_hvm_inject_trap {
+    vki_xen_domid_t domid;          /* IN */
+    vki_uint32_t vcpuid;            /* IN */
+    vki_uint32_t vector;            /* IN */
+    vki_uint32_t type;              /* IN */
+    vki_uint32_t error_code;        /* IN */
+    vki_uint32_t insn_len;          /* IN */
+    vki_xen_uint64_aligned_t cr2;   /* IN */
+};
+
+/* Handle identifying the ioreq server. */
+typedef vki_uint32_t vki_xen_ioservid_t;
+
+#define VKI_XEN_HVMOP_register_ioreq_server 20
+struct vki_xen_hvm_register_ioreq_server {
+    vki_xen_domid_t domid;  /* IN */
+    vki_xen_ioservid_t id;  /* OUT */
+};
+
+#define VKI_XEN_HVMOP_get_ioreq_server_buf_channel 21
+struct vki_xen_hvm_get_ioreq_server_buf_channel {
+    vki_xen_domid_t domid;          /* IN */
+    vki_xen_ioservid_t id;          /* IN */
+    vki_xen_evtchn_port_t channel;  /* OUT */
+};
+
+#define VKI_XEN_HVMOP_map_io_range_to_ioreq_server 22
+struct vki_xen_hvm_map_io_range_to_ioreq_server {
+    vki_xen_domid_t domid;      /* IN */
+    vki_uint8_t is_mmio;        /* IN */
+    vki_xen_ioservid_t id;      /* IN */
+    vki_xen_uint64_aligned_t s; /* IN */
+    vki_xen_uint64_aligned_t e; /* IN */
+};
+#define VKI_XEN_HVMOP_unmap_io_range_from_ioreq_server 23
+struct vki_xen_hvm_unmap_io_range_from_ioreq_server {
+    vki_xen_domid_t domid;          /* IN */
+    vki_uint8_t is_mmio;            /* IN */
+    vki_xen_ioservid_t id;          /* IN */
+    vki_xen_uint64_aligned_t addr;  /* IN */
+};
+#define VKI_XEN_HVMOP_register_pcidev 24
+struct vki_xen_hvm_register_pcidev {
+    vki_xen_domid_t domid;  /* IN */
+    vki_xen_ioservid_t id;  /* IN */
+    vki_uint16_t domain;    /* IN */
+    vki_uint8_t bus;        /* IN */
+    vki_uint8_t device;     /* IN */
+    vki_uint8_t function;   /* IN */
+};
+
+#endif // __VKI_XEN_HVM_H
 /*--------------------------------------------------------------------*/
 /*--- end                                                          ---*/
 /*--------------------------------------------------------------------*/
--- a/include/vki/vki-xen-memory.h	2013-10-23 11:49:54.000000000 +0100
+++ b/include/vki/vki-xen-memory.h	2014-01-08 18:33:52.000000000 +0000
@@ -22,6 +22,27 @@
 #define VKI_XENMEM_get_sharing_shared_pages   19
 #define VKI_XENMEM_claim_pages                24
 
+#define VKI_XENMEM_translate_gpfn_list	29
+#define VKI_XENMEM_release_mfn_list	30
+
+struct vki_xen_add_to_physmap {
+    /* In parameters. */
+    vki_xen_domid_t domid;
+    vki_uint16_t size;
+    unsigned int space;
+    vki_xen_ulong_t idx;
+    vki_xen_pfn_t gpfn;
+};
+
+struct vki_xen_translate_gpfn_list {
+    /* IN parameters */
+    vki_xen_domid_t domid;
+    vki_xen_ulong_t nr_gpfns;
+    VKI_XEN_GUEST_HANDLE(vki_xen_pfn_t) gpfn_list;
+    /* OUT parameter */
+    VKI_XEN_GUEST_HANDLE(vki_xen_pfn_t) mfn_list;
+};
+
 struct vki_xen_memory_map {
     unsigned int nr_entries;
     VKI_XEN_GUEST_HANDLE(void) buffer;
--- a/include/vki/vki-xen-sched.h	1970-01-01 01:00:00.000000000 +0100
+++ b/include/vki/vki-xen-sched.h	2014-01-08 18:37:45.000000000 +0000
@@ -0,0 +1,36 @@
+#ifndef __VKI_XEN_SCHED_H
+#define __VKI_XEN_SCHED_H
+
+#define VKI_XEN_SCHEDOP_yield           0
+#define VKI_XEN_SCHEDOP_block           1
+#define VKI_XEN_SCHEDOP_shutdown        2
+struct vki_xen_sched_shutdown {
+   unsigned int reason;
+};
+
+#define VKI_XEN_SCHEDOP_poll            3
+struct vki_xen_sched_poll {
+   VKI_XEN_GUEST_HANDLE(vki_xen_evtchn_port_t) ports;
+   unsigned int nr_ports;
+   vki_uint64_t timeout;
+};
+
+#define VKI_XEN_SCHEDOP_remote_shutdown 4
+struct vki_xen_sched_remote_shutdown {
+   vki_xen_domid_t domain_id;
+   unsigned int reason;
+};
+
+#define VKI_XEN_SCHEDOP_shutdown_code   5
+#define VKI_XEN_SCHEDOP_watchdog        6
+struct vki_xen_sched_watchdog {
+   vki_uint32_t id;
+   vki_uint32_t timeout;
+};
+
+
+#endif	// __VKI_XEN_SCHED_H
+/*--------------------------------------------------------------------*/
+/*--- end                                                          ---*/
+/*--------------------------------------------------------------------*/
+
