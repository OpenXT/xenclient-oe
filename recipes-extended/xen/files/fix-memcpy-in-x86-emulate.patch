################################################################################
SHORT DESCRIPTION: 
################################################################################
Make sure writebacks to guest memory are properly atomic

################################################################################
LONG DESCRIPTION: 
################################################################################
When running x86_emulate, the code that writes the results back to guest
memory must ensure that the proper atomicity guaranteed by the instructions
being emulated is maintained. memcpy provides for atomic quadword writes
but writes the last 1-7 bytes using single byte operations (rep movsb) so
32- and 16- bit updates are not done atomically.
 
This change uses specific atomic operations if the size is 4 or 2 bytes.

################################################################################
CHANGELOG 
################################################################################
Updated for Xen 4.9.

################################################################################
REMOVAL 
################################################################################

################################################################################
UPSTREAM PLAN
################################################################################

################################################################################
INTERNAL DEPENDENCIES 
################################################################################

################################################################################
PATCHES 
################################################################################
--- a/xen/arch/x86/hvm/hvm.c
+++ b/xen/arch/x86/hvm/hvm.c
@@ -3071,6 +3071,37 @@ void hvm_task_switch(
     hvm_unmap_entry(nptss_desc);
 }
 
+/*
+ * Routines to make __hvm_copy appropriate to use for copying the
+ * results of instruction emulation back to guest memory - these
+ * typically require 64-bit, 32-bit and 16-bit writes to be atomic
+ * whereas memcpy is only atomic for 64-bit writes. This is still
+ * not 100% correct since copies larger than 64-bits will not be
+ * atomic for the last 2-6 bytes but should be good enough for
+ * instruction emulation
+ */
+static inline void __hvm_atomic_copy(
+    void *to, const void *from, size_t count)
+{
+    if (count == sizeof(uint32_t))
+        *(uint32_t *)to = *(uint32_t *)from;
+    else if (count == sizeof(uint16_t))
+        *(uint16_t *)to = *(uint16_t *)from;
+    else
+        memcpy(to, from, count);
+}
+
+static inline void __hvm_atomic_zero(
+    void *to, size_t count)
+{
+    if (count == sizeof(int32_t))
+        *(int32_t *)to = (int32_t)0;
+    else if (count == sizeof(int16_t))
+        *(int16_t *)to = (int16_t)0;
+    else
+        memset(to, 0, count);
+}
+
 #define HVMCOPY_from_guest (0u<<0)
 #define HVMCOPY_to_guest   (1u<<0)
 #define HVMCOPY_phys       (0u<<2)
@@ -3180,9 +3211,9 @@ static enum hvm_copy_result __hvm_copy(
             else
             {
                 if ( buf )
-                    memcpy(p, buf, count);
+                    __hvm_atomic_copy(p, buf, count);
                 else
-                    memset(p, 0, count);
+                    __hvm_atomic_zero(p, count);
                 paging_mark_dirty(v->domain, _mfn(page_to_mfn(page)));
             }
         }
--- a/xen/arch/x86/mm/shadow/multi.c
+++ b/xen/arch/x86/mm/shadow/multi.c
@@ -4770,6 +4770,26 @@ static void emulate_unmap_dest(struct vc
     sh_emulate_unmap_dest(v, addr, bytes, sh_ctxt);
 }
 
+/*
+ * Routine to make sh_x86_emulate_write appropriate to use for copying the
+ * results of instruction emulation back to guest memory - these
+ * typically require 64-bit, 32-bit and 16-bit writes to be atomic
+ * whereas memcpy is only atomic for 64-bit writes. This is still
+ * not 100% correct since copies larger than 64-bits will not be
+ * atomic for the last 2-6 bytes but should be good enough for
+ * instruction emulation
+ */
+static inline void __sh_atomic_write(
+    void *to, const void *from, size_t count)
+{
+    if (count == sizeof(uint32_t))
+        *(uint32_t *)to = *(uint32_t *)from;
+    else if (count == sizeof(uint16_t))
+        *(uint16_t *)to = *(uint16_t *)from;
+    else
+        memcpy(to, from, count);
+}
+
 static int
 sh_x86_emulate_write(struct vcpu *v, unsigned long vaddr, void *src,
                      u32 bytes, struct sh_emulate_ctxt *sh_ctxt)
@@ -4785,7 +4805,7 @@ sh_x86_emulate_write(struct vcpu *v, uns
         return (long)addr;
 
     paging_lock(v->domain);
-    memcpy(addr, src, bytes);
+    __sh_atomic_write(addr, src, bytes);
 
     if ( tb_init_done )
     {
