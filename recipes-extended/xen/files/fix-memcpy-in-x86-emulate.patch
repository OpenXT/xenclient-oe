################################################################################
SHORT DESCRIPTION: 
################################################################################
Make sure writebacks to guest memory are properly atomic

################################################################################
LONG DESCRIPTION: 
################################################################################
When running x86_emulate, the code that writes the results back to guest
memory must ensure that the proper atomicity guaranteed by the instructions
being emulated is maintained. memcpy provides for atomic quadword writes
but writes the last 1-7 bytes using single byte operations (rep movsb) so
32- and 16- bit updates are not done atomically.
 
This change uses specific atomic operations if the size is 4 or 2 bytes.

################################################################################
CHANGELOG 
################################################################################

################################################################################
REMOVAL 
################################################################################

################################################################################
UPSTREAM PLAN
################################################################################

################################################################################
INTERNAL DEPENDENCIES 
################################################################################

################################################################################
PATCHES 
################################################################################
--- a/xen/arch/x86/hvm/hvm.c
+++ b/xen/arch/x86/hvm/hvm.c
@@ -4162,6 +4162,26 @@ void hvm_task_switch(
     hvm_unmap_entry(nptss_desc);
 }
 
+/*
+ * Routine to make __hvm_copy appropriate to use for copying the
+ * results of instruction emulation back to guest memory - these
+ * typically require 64-bit, 32-bit and 16-bit writes to be atomic
+ * whereas memcpy is only atomic for 64-bit writes. This is still
+ * not 100% correct since copies larger than 64-bits will not be
+ * atomic for the last 2-6 bytes but should be good enough for
+ * instruction emulation
+ */
+static inline void __hvm_atomic_copy(
+    void *to, void *from, int count)
+{
+    if (count == sizeof(uint32_t))
+        *(uint32_t *)to = *(uint32_t *)from;
+    else if (count == sizeof(uint16_t))
+        *(uint16_t *)to = *(uint16_t *)from;
+    else
+        memcpy(to, from, count);
+}
+
 #define HVMCOPY_from_guest (0u<<0)
 #define HVMCOPY_to_guest   (1u<<0)
 #define HVMCOPY_no_fault   (0u<<1)
@@ -4267,7 +4287,7 @@ static enum hvm_copy_result __hvm_copy(
             }
             else
             {
-                memcpy(p, buf, count);
+                __hvm_atomic_copy(p, buf, count);
                 paging_mark_dirty(curr->domain, page_to_mfn(page));
             }
         }
--- a/xen/arch/x86/mm/shadow/multi.c
+++ b/xen/arch/x86/mm/shadow/multi.c
@@ -4794,6 +4794,26 @@ static void emulate_unmap_dest(struct vc
     atomic_inc(&v->domain->arch.paging.shadow.gtable_dirty_version);
 }
 
+/*
+ * Routine to make sh_x86_emulate_write appropriate to use for copying the
+ * results of instruction emulation back to guest memory - these
+ * typically require 64-bit, 32-bit and 16-bit writes to be atomic
+ * whereas memcpy is only atomic for 64-bit writes. This is still
+ * not 100% correct since copies larger than 64-bits will not be
+ * atomic for the last 2-6 bytes but should be good enough for
+ * instruction emulation
+ */
+static inline void __sh_atomic_write(
+    void *to, void *from, int count)
+{
+    if (count == sizeof(uint32_t))
+        *(uint32_t *)to = *(uint32_t *)from;
+    else if (count == sizeof(uint16_t))
+        *(uint16_t *)to = *(uint16_t *)from;
+    else
+        memcpy(to, from, count);
+}
+
 static int
 sh_x86_emulate_write(struct vcpu *v, unsigned long vaddr, void *src,
                      u32 bytes, struct sh_emulate_ctxt *sh_ctxt)
@@ -4809,7 +4829,7 @@ sh_x86_emulate_write(struct vcpu *v, uns
         return (long)addr;
 
     paging_lock(v->domain);
-    memcpy(addr, src, bytes);
+    __sh_atomic_write(addr, src, bytes);
 
     if ( tb_init_done )
     {
