################################################################################
SHORT DESCRIPTION: 
################################################################################
Make sure writebacks to guest memory are properly atomic

################################################################################
LONG DESCRIPTION: 
################################################################################
When running x86_emulate, the code that writes the results back to guest
memory must ensure that the proper atomicity guaranteed by the instructions
being emulated is maintained. memcpy provides for atomic quadword writes
but writes the last 1-7 bytes using single byte operations (rep movsb) so
32- and 16- bit updates are not done atomically.
 
This change uses specific atomic operations if the size is 4 or 2 bytes.

################################################################################
CHANGELOG 
################################################################################
Updated for Xen 4.9.

################################################################################
REMOVAL 
################################################################################

################################################################################
UPSTREAM PLAN
################################################################################

################################################################################
INTERNAL DEPENDENCIES 
################################################################################

################################################################################
PATCHES 
################################################################################
--- a/xen/arch/x86/hvm/hvm.c
+++ b/xen/arch/x86/hvm/hvm.c
@@ -3165,6 +3165,37 @@ enum hvm_translation_result hvm_translat
     return HVMTRANS_okay;
 }
 
+/*
+ * Routines to make __hvm_copy appropriate to use for copying the
+ * results of instruction emulation back to guest memory - these
+ * typically require 64-bit, 32-bit and 16-bit writes to be atomic
+ * whereas memcpy is only atomic for 64-bit writes. This is still
+ * not 100% correct since copies larger than 64-bits will not be
+ * atomic for the last 2-6 bytes but should be good enough for
+ * instruction emulation
+ */
+static inline void __hvm_atomic_copy(
+    void *to, const void *from, size_t count)
+{
+    if (count == sizeof(uint32_t))
+        *(uint32_t *)to = *(uint32_t *)from;
+    else if (count == sizeof(uint16_t))
+        *(uint16_t *)to = *(uint16_t *)from;
+    else
+        memcpy(to, from, count);
+}
+
+static inline void __hvm_atomic_zero(
+    void *to, size_t count)
+{
+    if (count == sizeof(int32_t))
+        *(int32_t *)to = (int32_t)0;
+    else if (count == sizeof(int16_t))
+        *(int16_t *)to = (int16_t)0;
+    else
+        memset(to, 0, count);
+}
+
 #define HVMCOPY_from_guest (0u<<0)
 #define HVMCOPY_to_guest   (1u<<0)
 #define HVMCOPY_phys       (0u<<2)
@@ -3231,9 +3262,9 @@ static enum hvm_translation_result __hvm
             else
             {
                 if ( buf )
-                    memcpy(p, buf, count);
+                    __hvm_atomic_copy(p, buf, count);
                 else
-                    memset(p, 0, count);
+                    __hvm_atomic_zero(p, count);
                 paging_mark_pfn_dirty(v->domain, _pfn(gfn_x(gfn)));
             }
         }
--- a/xen/arch/x86/mm/shadow/hvm.c
+++ b/xen/arch/x86/mm/shadow/hvm.c
@@ -182,6 +182,26 @@ hvm_emulate_insn_fetch(enum x86_segment
     return X86EMUL_OKAY;
 }
 
+/*
+ * Routine to make hvm_emulate_write appropriate to use for copying the
+ * results of instruction emulation back to guest memory - these
+ * typically require 64-bit, 32-bit and 16-bit writes to be atomic
+ * whereas memcpy is only atomic for 64-bit writes. This is still
+ * not 100% correct since copies larger than 64-bits will not be
+ * atomic for the last 2-6 bytes but should be good enough for
+ * instruction emulation
+ */
+static inline void __sh_atomic_write(
+    void *to, const void *from, size_t count)
+{
+    if (count == sizeof(uint32_t))
+        *(uint32_t *)to = *(uint32_t *)from;
+    else if (count == sizeof(uint16_t))
+        *(uint16_t *)to = *(uint16_t *)from;
+    else
+        memcpy(to, from, count);
+}
+
 static int
 hvm_emulate_write(enum x86_segment seg,
                   unsigned long offset,
@@ -214,7 +234,7 @@ hvm_emulate_write(enum x86_segment seg,
         return ~PTR_ERR(ptr);
 
     paging_lock(v->domain);
-    memcpy(ptr, p_data, bytes);
+    __sh_atomic_write(ptr, p_data, bytes);
 
     if ( tb_init_done )
         v->arch.paging.mode->shadow.trace_emul_write_val(ptr, addr,
