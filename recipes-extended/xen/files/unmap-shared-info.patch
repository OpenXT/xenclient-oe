################################################################################
SHORT DESCRIPTION: 
################################################################################
XENMAPSPACE_shared_info can also unmmap the shinfo page

################################################################################
LONG DESCRIPTION: 
################################################################################
When hibernating/resuming from disk HVM linux guests, there is the
situation where the booting domU linux kernel requests via a hypercall
its shared info page mapping but the just resumed from hibernation  kernel
has no idea what that page was and it may inadvertently use the old shared info
mapping - thinking it is a free page (when in fact is not).
 
Therefore before freezing, the booting kernel has to restore(undo) its
shared info mapping so the hypercall involving XENMAPSPACE_shared_info
has now the ability to undo the operation if the xatp.gpfn field is
passed the "magic" value INVALID_MFN.

################################################################################
CHANGELOG 
################################################################################

################################################################################
REMOVAL 
################################################################################

################################################################################
UPSTREAM PLAN
################################################################################

################################################################################
INTERNAL DEPENDENCIES 
################################################################################

################################################################################
PATCHES 
################################################################################
--- a/xen/arch/x86/mm.c
+++ b/xen/arch/x86/mm.c
@@ -5239,6 +5239,8 @@ int xenmem_add_to_physmap_one(
     unsigned long prev_mfn, mfn = 0, old_gpfn;
     int rc = 0;
     p2m_type_t p2mt;
+    int unmap_shinfo = 0;
+    xen_pfn_t gpfn_new = gfn_x(gpfn);
 
     if ( !paging_mode_translate(d) )
         return -EACCES;
@@ -5248,6 +5250,11 @@ int xenmem_add_to_physmap_one(
         case XENMAPSPACE_shared_info:
             if ( idx == 0 )
                 mfn = virt_to_mfn(d->shared_info);
+            /* unmap shared info page if guest passed INVALID_MFN */
+            if ( gpfn_new == (hvm_guest_x86_mode(current) == 8
+                              ? mfn_x(INVALID_MFN)
+                              : mfn_x(INVALID_MFN) >> 32) )
+                unmap_shinfo = 1;
             break;
         case XENMAPSPACE_grant_table:
             grant_write_lock(d->grant_table);
@@ -5303,24 +5310,35 @@ int xenmem_add_to_physmap_one(
     {
         if ( page )
             put_page(page);
+        if ( unmap_shinfo )
+        {
+            if ( d->prev_mfn_shinfo != mfn_x(INVALID_MFN) &&
+                 d->prev_gpfn_shinfo != mfn_x(INVALID_MFN) )
+            {
+                gpfn_new = d->prev_gpfn_shinfo;
+                mfn = d->prev_mfn_shinfo;
+            }
+            else
+                printk("unmapping of shared info requested while not mapped\n");
+        }
         if ( space == XENMAPSPACE_gmfn || space == XENMAPSPACE_gmfn_range )
             put_gfn(d, gfn);
         return -EINVAL;
     }
 
     /* Remove previously mapped page if it was present. */
-    prev_mfn = mfn_x(get_gfn(d, gfn_x(gpfn), &p2mt));
+    prev_mfn = mfn_x(get_gfn(d, gpfn_new, &p2mt));
     if ( mfn_valid(_mfn(prev_mfn)) )
     {
         if ( is_xen_heap_mfn(prev_mfn) )
             /* Xen heap frames are simply unhooked from this phys slot. */
-            rc = guest_physmap_remove_page(d, gpfn, _mfn(prev_mfn), PAGE_ORDER_4K);
-        else
+            rc = guest_physmap_remove_page(d, _gfn(gpfn_new), _mfn(prev_mfn), PAGE_ORDER_4K);
+        else if ( space != XENMAPSPACE_shared_info )
             /* Normal domain memory is freed, to avoid leaking memory. */
-            rc = guest_remove_page(d, gfn_x(gpfn));
+            rc = guest_remove_page(d, gpfn_new);
     }
     /* In the XENMAPSPACE_gmfn case we still hold a ref on the old page. */
-    put_gfn(d, gfn_x(gpfn));
+    put_gfn(d, gpfn_new);
 
     if ( rc )
         goto put_both;
@@ -5339,13 +5357,28 @@ int xenmem_add_to_physmap_one(
 
     /* Map at new location. */
     if ( !rc )
-        rc = guest_physmap_add_page(d, gpfn, _mfn(mfn), PAGE_ORDER_4K);
+        rc = guest_physmap_add_page(d, _gfn(gpfn_new), _mfn(mfn), PAGE_ORDER_4K);
 
  put_both:
     /* In the XENMAPSPACE_gmfn, we took a ref of the gfn at the top */
     if ( space == XENMAPSPACE_gmfn || space == XENMAPSPACE_gmfn_range )
         put_gfn(d, gfn);
 
+    if ( space == XENMAPSPACE_shared_info )
+    {
+        /* save the shared info mapping to restore, if we are not unmapping */
+        if (!unmap_shinfo)
+        {
+            d->prev_mfn_shinfo = prev_mfn;
+            d->prev_gpfn_shinfo = gpfn_new;
+        }
+        else
+        {
+            d->prev_mfn_shinfo = mfn_x(INVALID_MFN);
+            d->prev_gpfn_shinfo = mfn_x(INVALID_MFN);
+        }
+    }
+
     if ( page )
         put_page(page);
 
--- a/xen/common/domain.c
+++ b/xen/common/domain.c
@@ -402,6 +402,9 @@ struct domain *domain_create(domid_t dom
         spin_unlock(&domlist_update_lock);
     }
 
+    d->prev_mfn_shinfo = mfn_x(INVALID_MFN);
+    d->prev_gpfn_shinfo = mfn_x(INVALID_MFN);
+
     return d;
 
  fail:
--- a/xen/include/xen/sched.h
+++ b/xen/include/xen/sched.h
@@ -476,6 +476,10 @@ struct domain
     unsigned int last_alloc_node;
     spinlock_t node_affinity_lock;
 
+    /* Used for unmapping the shinfo page */
+    unsigned long prev_mfn_shinfo;
+    unsigned long prev_gpfn_shinfo;
+
     /* vNUMA topology accesses are protected by rwlock. */
     rwlock_t vnuma_rwlock;
     struct vnuma_info *vnuma;
