################################################################################
SHORT DESCRIPTION: 
################################################################################
XENMAPSPACE_shared_info can also unmmap the shinfo page

################################################################################
LONG DESCRIPTION: 
################################################################################
When hibernating/resuming from disk HVM linux guests, there is the
situation where the booting domU linux kernel requests via a hypercall
its shared info page mapping but the just resumed from hibernation  kernel
has no idea what that page was and it may inadvertently use the old shared info
mapping - thinking it is a free page (when in fact is not).
 
Therefore before freezing, the booting kernel has to restore(undo) its
shared info mapping so the hypercall involving XENMAPSPACE_shared_info
has now the ability to undo the operation if the xatp.gpfn field is
passed the "magic" value INVALID_MFN.

################################################################################
CHANGELOG 
################################################################################

################################################################################
REMOVAL 
################################################################################

################################################################################
UPSTREAM PLAN
################################################################################

################################################################################
INTERNAL DEPENDENCIES 
################################################################################

################################################################################
PATCHES 
################################################################################
--- a/xen/common/domain.c
+++ b/xen/common/domain.c
@@ -482,6 +482,9 @@ struct domain *domain_create(domid_t dom
         memcpy(d->handle, config->handle, sizeof(d->handle));
     }
 
+    d->prev_mfn_shinfo = mfn_x(INVALID_MFN);
+    d->prev_gpfn_shinfo = mfn_x(INVALID_MFN);
+
     return d;
 
  fail:
--- a/xen/include/xen/sched.h
+++ b/xen/include/xen/sched.h
@@ -482,6 +482,10 @@ struct domain
     unsigned int last_alloc_node;
     spinlock_t node_affinity_lock;
 
+    /* Used for unmapping the shinfo page */
+    unsigned long prev_mfn_shinfo;
+    unsigned long prev_gpfn_shinfo;
+
     /* vNUMA topology accesses are protected by rwlock. */
     rwlock_t vnuma_rwlock;
     struct vnuma_info *vnuma;
--- a/xen/arch/x86/mm.c
+++ b/xen/arch/x86/mm.c
@@ -119,6 +119,7 @@
 #include <xen/efi.h>
 #include <xen/grant_table.h>
 #include <xen/hypercall.h>
+#include <asm/hvm/hvm.h>
 #include <asm/paging.h>
 #include <asm/shadow.h>
 #include <asm/page.h>
@@ -4469,6 +4470,9 @@ int xenmem_add_to_physmap_one(
     int rc = 0;
     mfn_t mfn = INVALID_MFN;
     p2m_type_t p2mt;
+    int unmap_shinfo = 0;
+    xen_pfn_t gpfn_new = gfn_x(gpfn);
+
 
     if ( !paging_mode_translate(d) )
         return -EACCES;
@@ -4478,6 +4482,13 @@ int xenmem_add_to_physmap_one(
         case XENMAPSPACE_shared_info:
             if ( idx == 0 )
                 mfn = virt_to_mfn(d->shared_info);
+#ifdef CONFIG_HVM
+            /* unmap shared info page if guest passed INVALID_MFN */
+            if ( gpfn_new == (hvm_guest_x86_mode(current) == 8
+                              ? mfn_x(INVALID_MFN)
+                              : mfn_x(INVALID_MFN) >> 32) )
+                unmap_shinfo = 1;
+#endif
             break;
         case XENMAPSPACE_grant_table:
             rc = gnttab_map_frame(d, idx, gpfn, &mfn);
@@ -4507,25 +4518,26 @@ int xenmem_add_to_physmap_one(
             break;
     }
 
+    /* Remove previously mapped page if it was present. */
+    prev_mfn = mfn_x(get_gfn(d, gpfn_new, &p2mt));
+
     if ( mfn_eq(mfn, INVALID_MFN) )
     {
         rc = -EINVAL;
         goto put_both;
     }
 
-    /* Remove previously mapped page if it was present. */
-    prev_mfn = mfn_x(get_gfn(d, gfn_x(gpfn), &p2mt));
     if ( mfn_valid(_mfn(prev_mfn)) )
     {
         if ( is_xen_heap_mfn(prev_mfn) )
             /* Xen heap frames are simply unhooked from this phys slot. */
-            rc = guest_physmap_remove_page(d, gpfn, _mfn(prev_mfn), PAGE_ORDER_4K);
-        else
+            rc = guest_physmap_remove_page(d, _gfn(gpfn_new), _mfn(prev_mfn), PAGE_ORDER_4K);
+        else if ( space != XENMAPSPACE_shared_info )
             /* Normal domain memory is freed, to avoid leaking memory. */
-            rc = guest_remove_page(d, gfn_x(gpfn));
+            rc = guest_remove_page(d, gpfn_new);
     }
     /* In the XENMAPSPACE_gmfn case we still hold a ref on the old page. */
-    put_gfn(d, gfn_x(gpfn));
+    put_gfn(d, gpfn_new);
 
     if ( rc )
         goto put_both;
@@ -4543,13 +4555,28 @@ int xenmem_add_to_physmap_one(
 
     /* Map at new location. */
     if ( !rc )
-        rc = guest_physmap_add_page(d, gpfn, mfn, PAGE_ORDER_4K);
+        rc = guest_physmap_add_page(d, _gfn(gpfn_new), mfn, PAGE_ORDER_4K);
 
  put_both:
     /* In the XENMAPSPACE_gmfn case, we took a ref of the gfn at the top. */
     if ( space == XENMAPSPACE_gmfn )
         put_gfn(d, gfn);
 
+    if ( space == XENMAPSPACE_shared_info || unmap_shinfo )
+    {
+        /* save the shared info mapping to restore, if we are not unmapping */
+        if (!unmap_shinfo)
+        {
+            d->prev_mfn_shinfo = prev_mfn;
+            d->prev_gpfn_shinfo = gpfn_new;
+        }
+        else
+        {
+            d->prev_mfn_shinfo = mfn_x(INVALID_MFN);
+            d->prev_gpfn_shinfo = mfn_x(INVALID_MFN);
+        }
+    }
+
     if ( page )
         put_page(page);
 
